{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37006b4a-2886-4c8e-9f3a-529ceb4ab96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn base classes for building custom transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# sklearn preprocessing tools\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# sklearn pipeline tools\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0a13cef-d0b4-4fbe-a808-ec219813d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric features used in logistic regression\n",
    "numeric_features = [\n",
    "    'name_email_similarity',\n",
    "    'credit_risk_score',\n",
    "    'proposed_credit_limit',\n",
    "    'intended_balcon_amount',\n",
    "    'prev_address_months_count',\n",
    "    'date_of_birth_distinct_emails_4w',\n",
    "    'current_address_months_count',\n",
    "    'device_distinct_emails_8w',\n",
    "    'income',\n",
    "    'customer_age'\n",
    "]\n",
    "# categorical features used in logistic regression\n",
    "categorical_features = [\n",
    "    'prev_address_months_count_missing',\n",
    "    'bank_months_count_missing',\n",
    "    'intended_balcon_amount_missing',\n",
    "    'foreign_request',\n",
    "    'housing_status',\n",
    "    'payment_type',\n",
    "    'device_os',\n",
    "    'keep_alive_session',\n",
    "    'has_other_cards',\n",
    "    'phone_home_valid',\n",
    "    'source'\n",
    "]\n",
    "# columns where negative values represent missing\n",
    "negative_missing_cols = [\n",
    "    'prev_address_months_count',\n",
    "    'current_address_months_count',\n",
    "    'bank_months_count',\n",
    "    'device_distinct_emails_8w',\n",
    "    'intended_balcon_amount',\n",
    "    'session_length_in_minutes'\n",
    "]\n",
    "# skewed columns requiring log transform\n",
    "log_features = [\n",
    "    'proposed_credit_limit',\n",
    "    'intended_balcon_amount',\n",
    "    'current_address_months_count',\n",
    "    'prev_address_months_count',\n",
    "    'device_distinct_emails_8w'\n",
    "]\n",
    "# missing indicator columns to combine\n",
    "missing_indicator_cols = [\n",
    "    'intended_balcon_amount_missing',\n",
    "    'prev_address_months_count_missing',\n",
    "    'bank_months_count_missing'\n",
    "]\n",
    "# columns to drop to avoid multicollinearity and insignificant predictors\n",
    "drop_features = [\n",
    "    'payment_type_AC',\n",
    "    'intended_balcon_amount_missing',\n",
    "    'prev_address_months_count_missing',\n",
    "    'bank_months_count_missing',\n",
    "    'intended_balcon_amount',\n",
    "    'prev_address_months_count',\n",
    "    'housing_status_BG',\n",
    "    'payment_type_AE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eddce349-32e8-4aab-9ade-ab5cecdbe3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeToNaNTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns):\n",
    "        # store columns where negative values indicate missing\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # nothing to learn here, just return self\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        # create copy to avoid modifying original dataframe\n",
    "        X = X.copy()\n",
    "        # replace negative values with NaN\n",
    "        for col in self.columns:\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].mask(X[col] < 0, np.nan)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c32f3a59-4564-432f-9d2a-c4a8bd6e0aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns):\n",
    "        # store columns to log transform\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col in X.columns:\n",
    "                X[col] = np.log1p(X[col])         \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef7d6b71-3fc7-41c8-80a8-12f77ff516ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingIndicatorCombiner(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, indicator_columns):\n",
    "        self.indicator_columns = indicator_columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # create combined indicator\n",
    "        X['is_incomplete'] = X[self.indicator_columns].max(axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "051d69aa-435f-4b58-8fb2-602f04c41c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDropper(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X = X.copy() \n",
    "        # drop columns if present\n",
    "        X = X.drop(columns=[col for col in self.columns if col in X.columns])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712601cb-f1ad-49a3-a6a9-1b58f095e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipeline = Pipeline([\n",
    "    # step 1: convert negative values to NaN\n",
    "    (\"negative_to_nan\", NegativeToNaNTransformer(negative_missing_cols)),\n",
    "    # step 2: impute missing using median\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    # step 3: log transform skewed variables\n",
    "    (\"log_transform\", LogTransformer(log_features)),\n",
    "    # step 4: scale features for logistic regression\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "282121ea-e4bd-4793-8d8f-6277966772b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipeline = Pipeline([\n",
    "    # one hot encoding\n",
    "    OneHotEncoder(\n",
    "        drop=\"first\",              # prevents dummy variable trap\n",
    "        handle_unknown=\"ignore\",  # prevents test set errors\n",
    "        sparse_output=False       # returns dataframe-like output\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4328cd91-bad4-46bf-bc3d-7788b550a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    (\"numeric\", numeric_pipeline, numeric_features),\n",
    "    (\"categorical\", categorical_pipeline, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4403e5e9-6237-43a0-a283-de8e4f09b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_preprocessor = Pipeline([\n",
    "    # combine missing indicators\n",
    "    (\"combine_missing\", MissingIndicatorCombiner(missing_indicator_cols)),\n",
    "    # apply numeric and categorical transformations\n",
    "    (\"column_processing\", preprocessor),\n",
    "    # drop unwanted features\n",
    "    (\"feature_drop\", FeatureDropper(drop_features))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f24ae75-c8e3-4097-8dd6-9f8051a11ad4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# FIT ONLY ON TRAIN DATA (CRITICAL FOR NO LEAKAGE)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_train_processed = logistic_preprocessor.fit_transform(\u001b[43mX_train\u001b[49m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# APPLY SAME TRANSFORM TO TEST DATA\u001b[39;00m\n\u001b[32m      4\u001b[39m X_test_processed = logistic_preprocessor.transform(X_test)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# FIT ONLY ON TRAIN DATA (CRITICAL FOR NO LEAKAGE)\n",
    "X_train_processed = logistic_preprocessor.fit_transform(X_train)\n",
    "# APPLY SAME TRANSFORM TO TEST DATA\n",
    "X_test_processed = logistic_preprocessor.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
